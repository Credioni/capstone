# Project Schedule


| First Week    | Second Week   | Third Week   | Fourth Week |
| ------------- | ------------- |------------- |-------------|
| Content Cell  | Content       | Content      |  Content    |


1. Implement a basic text-based RAG model using LangChain.
2. Enhance retrieval with multimodal embeddings (OpenAI CLIP for images, Whisper for audio
transcripts).
3. Use FAISS for vector-based retrieval of images, videos, and text data.
4. Develop a research assistant UI that allows users to enter text queries and get relevant text,
images, and video sources.
5. Fine-tune retrieval strategies for scientific literature by integrating the arXiv dataset.
6. Evaluate accuracy by comparing AI retrieval against traditional document search.

# Project 17: Multimedia Large Language Model Applications with Multimedia Embedding RAG

## Basic Idea
RAG models primarily focus on text-based retrieval, limiting their effectiveness in multimedia
applications. This project enhances RAG with multimodal retrieval by incorporating image, video, and
text embeddings. By integrating image and text embeddings in queries, the system enables faster and
more efficient retrieval, even on low-bandwidth networks. The use of compact embeddings ensures
quick access to relevant multimedia content, making AI-generated responses more contextually rich
and diverse

## Application
Create a scientific research assistant that retrieves related text, images, and videos from academic
papers.

